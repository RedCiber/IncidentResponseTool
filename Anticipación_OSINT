Para algunos la anticipación no es necesaria en el concepto RRA (Responder, Reaccionar y Anticipar), en respuesta a incientes es importante tener en cuenta estos factores para poder generar información de inteligencia que permita asocia una amenaza reciente para evitar un incidente.

Búsquedas OSINT:


>>>>https://inteltechniques.com/
>>>>https://nitinpandey.in/ihunt/
>>>>https://osint.link/#leak
>>>>

WINDOWS:

Busqueda de metadatos en Documentos Engine: 
------https://whereisdoc.com/
------http://www.doc-txt.com/
------https://www.documentcloud.org/home


IP address, Hash Values,domains,URL’s and file information

Below are some of the OSINT tools and their links …

Virustotal: https://www.virustotal.com/gui/home/upload

AbuseIPDB : https://www.abuseipdb.com/

IBM X-Force Exchange: https://exchange.xforce.ibmcloud.com/

AlienValut: https://otx.alienvault.com/dashboard/new

BGP Tool kit: https://bgp.he.net/

Whois lookup: whois.doamintools.com

check website is malicious/scam: https://www.urlvoid.com/

Site review: https://sitereview.bluecoat.com/

Url testing: https://trustedsource.org/

Sucuri:https://sitecheck.sucuri.net/

Cross-Browser testing: https://www.browserling.com/

Compendio SANS Intelligence: https://www.sans.org/blog/geolocation-resources-for-osint-investigations/


OSINT Framework

-----https://osintframework.com/

Google Dorks Conocidos: https://antoniogonzalezm.es/google-hacking-46-ejemplos-hacker-contrasenas-usando-google-enemigo-peor/


-----------------------------------------

# Importar las bibliotecas necesarias
import requests
from bs4 import BeautifulSoup

# Lista de los principales dorks de seguridad para búsqueda
dorks = [
    'intitle:"Index of /"',
    'ext:sql intext:"MySQL dump"',
    'filetype:log inurl:"password.log"',
    'intitle:"Index of /" "config.yml"',
    'filetype:env intext:APP_ENV',
    'ext:xml | ext:conf | ext:cnf | ext:reg | ext:inf "password"',
    'intext:"Index of /" (front-end | back-end | admin)',
    'intitle:"Index of /" inurl:ftp',
    'intitle:"Index of /" inurl:backup'
]

# Función para buscar y validar posibles fugas de información
def buscar_fugas(palabra):
    url = f"https://www.google.com/search?q={palabra}"
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    response = requests.get(url, headers=headers)
    
    if response.status_code == 200:
        print(f"Resultados para la palabra clave: {palabra}")
        print("--------------")
        soup = BeautifulSoup(response.text, 'html.parser')
        search_results = soup.find_all('a')
        urls_encontradas = [result.get('href') for result in search_results if result.get('href').startswith('http')]
        for url in urls_encontradas:
            print(url)
        print("\n")
    else:
        print(f"Error al realizar la búsqueda para la palabra clave: {palabra}")

# Ingresar la palabra clave de búsqueda
palabra_clave = input("Ingresa la palabra clave de búsqueda: ")

# Ejecutar la función para buscar posibles fugas de información para la palabra clave ingresada
buscar_fugas(palabra_clave)


